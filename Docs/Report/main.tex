\documentclass[12pt]{article}
\usepackage[pdftex]{graphicx} % Required for inserting images
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{float}
\usepackage{hyperref}
\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage{gensymb}
\usepackage{longtable}
\usepackage{array} % required for text wrapping in tables
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{indentfirst}
\usepackage{verbatim}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{thmtools}
\theoremstyle{definition}
\newtheorem{definition}{Definicja}
\theoremstyle{plain}
\newtheorem{theorem}{Twierdzenie}
\newtheorem{lemma}[theorem]{Lemat}
\begin{document}

    \title{
        \textbf{Teoria algorytmów i obliczeń} \\
        \large Projekt zaliczeniowy}

    \author
    {
        Piotr Jacak \\
        Jakub Kindracki \\
        Wiktor Kobielski \\
        Ernest Mołczan \\
        \\
        Koordynator: prof. dr hab. inż. Władysław Homenda
        \\
        \\
    }

    \date{Semestr zimowy 2025/2026}



    \begin{figure}
        \centering
        \includegraphics[width=1\linewidth]{mini.png}
    \end{figure}

    \maketitle

    \pagebreak
    \tableofcontents
    \pagebreak

% ---------------- WSTĘP ---------------- %


    \section{Wstęp}
    \label{sec:wstep}

    Niniejsza praca stanowi sprawozdanie z projektu zrealizowanego w ramach przedmiotu \textbf{Teoria algorytmów i obliczeń}. Przedmiotem badań są algorytmy operujące na multigrafach, ze szczególnym uwzględnieniem problematyki izomorfizmu podgrafów oraz minimalnych rozszerzeń grafów.

    Głównym celem projektu jest opracowanie, analiza teoretyczna oraz implementacja algorytmów rozwiązujących dwa ściśle powiązane problemy. Pierwszym z nich jest weryfikacja, czy dany multigraf $H$ jest izomorficzny z $n$ podgrafami multigrafu $G$. Drugim, kluczowym zagadnieniem, jest wyznaczenie \emph{minimalnego rozszerzenia} multigrafu $G$ do postaci $G'$, która zawiera co najmniej $n$ podgrafów izomorficznych z $H$.

    Realizacja powyższych celów wymagała formalnego zdefiniowania oraz uzasadnienia kilku fundamentalnych pojęć. W pracy zaproponowano autorskie lub bazujące na literaturze definicje:
    \begin{itemize}
        \item \emph{rozmiaru multigrafu},
        \item \emph{metryki} w zbiorze multigrafów,
        \item \emph{minimalnego rozszerzenia} multigrafu.
    \end{itemize}
    Pojęcia te stanowią podstawę do dalszej analizy algorytmicznej oraz oceny kosztu operacji.

    W ramach pracy przeprowadzono analizę złożoności obliczeniowej opracowanych algorytmów. Zgodnie z założeniami projektu, w przypadku gdy algorytmy dokładne charakteryzują się złożonością wykładniczą, przedstawiono również propozycje algorytmów aproksymacyjnych o złożoności wielomianowej.

% Niniejszy raport, oprócz formalnych definicji i analizy algorytmów, zawiera także opis przeprowadzonych testów obliczeniowych, dokumentację techniczną implementacji oraz wnioski końcowe.

    \pagebreak
% ---------------- WSTĘP ---------------- %

% ---------------- DEFINICJE ---------------- %


    \section{Definicje pojęć}
    \label{sec:definicje}

    \begin{definition}[Graf]
        Grafem nazywamy parę $G = (V, E)$, gdzie $V$ jest zbiorem wierzchołków, a $E \subseteq V \times V = \{(u, v) : u, v \in V \land u \neq v \}$ jest zbiorem krawędzi. Dla każdej pary wierzchołków $u, v \in V$ istnieje co najwyżej jedna krawędź łącząca wierzchołki $u$ i $v$.
    \end{definition}

    \begin{definition}[Multigraf]
        Multigrafem nazywamy graf, w którym pomiędzy dowolnymi dwoma różnymi wierzchołkami $u, v \in V$ może istnieć więcej niż jedna krawędź.
    \end{definition}

    \begin{definition}[Graf skierowany]
        Grafem skierowanym nazywamy parę $G = (V, E)$, gdzie $V$ jest zbiorem wierzchołków, a $E \subseteq V \times V = \{(u, v) : u, v \in V \land u \neq v \}$ jest zbiorem krawędzi. Krawędzie w grafie skierowanym mają określony kierunek, co oznacza, że krawędź $(u, v)$ jest różna od krawędzi $(v, u)$. Definicja jest analogiczna dla multigrafów.
    \end{definition}

    \begin{definition}[Izomorfizm grafów]
        Dwa grafy $G_1 = (V_1, E_1)$ i $G_2 = (V_2, E_2)$ są izomorficzne, wtedy i tylko wtedy, gdy istnieje bijekcja $f: V_1 \to V_2$, taka że dla każdej krawędzi $(u, v) \in E_1$ zachodzi $(f(u), f(v)) \in E_2$. Definicja ta jest analogiczna dla multigrafów i grafów skierowanych.
    \end{definition}

    \begin{definition}[Podgraf]
        Graf $H = (V_H, E_H)$ nazywamy podgrafem grafu $G = (V_G, E_G)$, wtedy i tylko wtedy, gdy $V_H \subseteq V_G$ oraz $E_H \subseteq E_G$. Definicja ta jest analogiczna dla multigrafów i grafów skierowanych.
    \end{definition}

    \begin{definition}[Macierz sąsiedztwa]
        Macierzą sąsiedztwa multigrafu $G = (V, E)$ nazywamy macierz $A$, której pole $A_{uv} = k$, wtedy i tylko wtedy, gdy istnieje $k$ krawędzi $(u, v) \in E$. W przypadku gdy nie istnieje żadna krawędź pomiędzy wierzchołkami $u$ i $v$, to $A_{uv} = 0$.
    \end{definition}

    \pagebreak
% ---------------- DEFINICJE ---------------- %

% ---------------- ROZMIAR MULTIGRAFU ---------------- %


    \section{Rozmiar multigrafu}
    \label{sec:rozmiar}

    \begin{definition}[Rozmiar multigrafu]
        Rozmiarem $S(G)$ multigrafu $G = (V, E)$ nazywamy parę liczb naturalnych $(|V|, |E|)$, gdzie $|V|$ oznacza liczbę wierzchołków, a $|E|$ liczbę krawędzi w multigrafie $G$.
    \end{definition}

    Zakładamy, że liczby wierzchołków i krawędzi są zapisanymi wcześniej stałymi, więc obliczenie rozmiaru multigrafów jest operacją o złożoności czasowej $O(1)$.

    \begin{definition}[Porządek w zbiorze wszystkich multigrafów]
        Niech $G_1$ i $G_2$ będą dwoma multigrafami. Mówimy, że $G_1$ jest mniejszy, lub równy $G_2$ wtedy i tylko wtedy, gdy:
        \[ |V_1| < |V_2| \lor (|V_1| = |V_2| \land |E_1| \leq |E_2|) \]
    \end{definition}

    Żeby udowodnić poprawność powyższej definicji porządku wykazujemy, że spełnia ona trzy wymagane własności:
    \begin{itemize}
        \item \textbf{Zwrotność}:
        \[S(G) \leq S(G)\]
        Dla dowolnego multigrafu $G = (V, E)$, zachodzi $|V| = |V| \land |E| = |E|$. Więc w szczególności spełnia on warunek $|V| = |V| \land |E| \leq |E|$ z definicji porządku. Stąd $S(G) \leq S(G)$.
        \item \textbf{Przechodniość}:
        \[S(G_1) \leq S(G_2) \land S(G_2) \leq S(G_3) \Rightarrow S(G_1) \leq S(G_3)\]
        Weźmy dowolne trzy multigrafy $G_1 = (V_1, E_1)$, $G_2 = (V_2, E_2)$ oraz $G_3 = (V_3, E_3)$ takie, że $S(G_1) \leq S(G_2)$ oraz $S(G_2) \leq S(G_3)$.

        Załóżmy, że $S(G_1) \geq S(G_3)$. Z definicji to implikuje, że $|V_1| > |V_3| \lor (|V_1| = |V_3| \land |E_1| > |E_3|)$.

        Z założeń wiemy też, że $|V_2| > |V_1|$, lub $|V_2| = |V_1| \land |E_2| \geq |E_1|$.

        W pierwszym przypadku z założeń wynika, ze $|V_2| > |V_3|$, co stoi w sprzeczności z $S(G_2) \leq S(G_3)$.

        W drugim przypadku, z założeń wynika, że $|V_2| = |V_3|$ oraz $|E_2| > |E_3|$, co również stoi w sprzeczności z $S(G_2) \leq S(G_3)$.

        W obu przypadkach dochodzimy do sprzeczności, więc nasze początkowe założenie było fałszywe. Stąd $S(G_1) \leq S(G_3)$.
        \item \textbf{Antysymetryczność}:
        \[S(G_1) \leq S(G_2) \land S(G_2) \leq S(G_1) \Rightarrow S(G_1) = S(G_2)\]
        Weźmy dowolne dwa multigrafy $G_1 = (V_1, E_1)$ oraz $G_2 = (V_2, E_2)$ takie, że $S(G_1) \leq S(G_2)$ oraz $S(G_2) \leq S(G_1)$. Z definicji porządku, z pierwszego założenia wynika, że $|V_1| < |V_2| \lor (|V_1| = |V_2| \land |E_1| \leq |E_2|)$. Z drugiego założenia wynika, że $|V_2| < |V_1| \lor (|V_2| = |V_1| \land |E_2| \leq |E_1|)$.

        Jeśli $|V_1| < |V_2|$, to z drugiego założenia wynika, że $|V_2| < |V_1|$, co jest sprzeczne. Analogicznie, jeśli $|V_2| < |V_1|$, to z pierwszego założenia wynika, że $|V_1| < |V_2|$, co również jest sprzeczne. Zatem musi zachodzić $|V_1| = |V_2|$.

        Wtedy z pierwszego założenia wynika, że $|E_1| \leq |E_2|$, a z drugiego, że $|E_2| \leq |E_1|$. Stąd $|E_1| = |E_2|$.

        W rezultacie mamy $S(G_1) = S(G_2)$.

    \end{itemize}

    \pagebreak
% ---------------- ROZMIAR MULTIGRAFU ---------------- %

% ---------------- METRYKA W ZBIORZE WSZYSTKICH MULTIGRAFÓW ---------------- %


    \section{Metryka w zbiorze wszystkich multigrafów}
    \label{sec:metryka}

    \begin{definition}[Metryka w zbiorze multigrafów]
        Niech $\mathcal{G}$ będzie zbiorem wszystkich multigrafów. \textbf{Metryką} w zbiorze $\mathcal{G}$ nazywamy funkcję:
        \[d: \mathcal{G} \times \mathcal{G} \to \mathbb{N}_0\]
        Wartość $d(G_1, G_2)$ nazywamy \textbf{odległością} między multigrafami $G_1$ i $G_2$, a definiujemy ją, jako \textbf{minimalną} liczbę operacji dodawania lub usuwania pojedynczej krawędzi lub wierzchołka, za pomocą których można przekształcić graf $G_1$ w graf izomorficzny z $G_2$.
    \end{definition}

% TODO: Sprawdzić i ewentualnie rozpisać dowody własności metryki
    Powyższa definicja spełnia następujące własności metryki:
    \begin{itemize}
        \item \textbf{Identyczność nierozróżnialnych}: \\
        Dla dowolnych multigrafów $G_1$ oraz $G_2$, $d(G_1, G_2) = 0$ wtedy i tylko wtedy, gdy $G_1$ jest izomorficzny z $G_2$. Wynika to bezpośrednio z definicji naszej metryki.
        \item \textbf{Symetria}: \\
        Dla dowolnych multigrafów $G_1$ oraz $G_2$, $d(G_1, G_2) = d(G_2, G_1)$. Dodawanie i usuwanie krawędzi lub wierzchołków jest operacją odwracalną, więc liczba operacji potrzebnych do przekształcenia $G_1$ w $G_2$ jest równa liczbie odwrotnych operacji potrzebnych do przekształcenia $G_2$ w $G_1$.
        \item \textbf{Nierówność trójkąta}: \\
        Dla dowolnych multigrafów $G_1$, $G_2$ oraz $G_3$, $d(G_1, G_3) \leq d(G_1, G_2) + d(G_2, G_3)$. Oznacza to, że najkrótsza droga między dwoma multigrafami nie może być dłuższa niż droga przechodząca przez trzeci multigraf. Jest to prawda, ponieważ każda sekwencja operacji przekształcających $G_1$ w $G_2$ oraz $G_2$ w $G_3$ może być złożona w jedną sekwencję przekształcającą $G_1$ w $G_3$.
    \end{itemize}

    \pagebreak
% ---------------- METRYKA W ZBIORZE WSZYSTKICH MULTIGRAFÓW ---------------- %

% ---------------- MINIMALNE ROZSZERZENIE MULTIGRAFU ---------------- %


    \section{Minimalne rozszerzenie multigrafu}
    \label{sec:minimalne_rozszerzenie}

    \subsection{Algorytm dokładny dla problemu izomorfizmu podgrafu}
    Mając dane dwa grafy G i H, chcemy znaleźć podgrafy G izomorficzne do H. Do rozwiązania tego problemu posłuży nam algorytm, który wykorzystuje procedurę Backtrackingu do sprawdzania struktury grafów. \\
    Przed przejściem do algorytmu, zdefiniujmy sobie struktury przydatne nam do implementacji. Niech $n_G = |V(G)|$ - ilość wierzchołków w grafie G oraz $n_H = |V(H)|$ - ilość wierzchołków w Grafie H. \\ \\
    \textbf{Opis algorytmu:}
    \begin{enumerate}
        \item Inicjalizacja macierzy sąsiedztwa grafów G i H odpowiednio $S_G \in \mathbb{N}^{n_G  \times  n_G}$ i $S_H \in \mathbb{N}^{n_H  \times  n_H}$. Wartość $S[i,j]$, to ilość krawędzi pomiędzy i-tym, a j-tym wierzchołkiem dla danego grafu.
        \item Inicjalizacja kandydatów - Zdefiniujmy sobie listę $mozliwe\_dopasowania$, \\ $len(mozliwe\_dopasowania) = n_H$, gdzie pod i-tym indeksem, będziemy mieli listę możliwych dopasowań dla wierzchołka $i \in V(H)$. \\
        Algorytm Ullmana dla grafów prostych zakłada inicjalizację: \\
        $u\in V(G),  u \in mozliwe\_dopasowania[i] \iff deg_G(u) \ge deg_H(i) $ \\
        Jest ona działającą inicjalizacją dla multigrafów, jednak w celach optymalizacji algorytmu, możemy zmienić tę inicjalizację tak, aby zmniejszyć liczbę potencjalnych dopasowań, a co za tym idzie zmniejszyć liczbę gałęzi, które będzie musiał przejść algorytm. Możemy zauważyć, że w macierzach sąsiedztwa na głównej przekątnej pod indeksami $[i,i]$ znajduje się liczba pętli danego wierzchołka, zatem naszym warunkiem będzie także $S_G[i,i] \ge S_H[i,i]$. Biorąc to wszystko razem, otrzymujemy \\
        $u \in mozliwe\_dopasowania[i] \iff (deg_G(u) \ge deg_H(i)) \land  (S_G[i,i] \ge S_H[i,i]))$
        \item
        Dla każdej krawędzi, która istnieje między już dopasowanymi wierzchołkami z H, sprawdź czy istnieje krawędź między ich dopasowaniami z G i czy ilość krawędzi między dopasowaniami jest większa lub równa niż ilość krawędzi między wierzchołkami. Można to osiągnąć przez przejrzenie wszystkich par już dopasowanych wierzchołków i krawędzi między nimi. Jeśli nie, zwróć False
        \item
        Sprawdź, czy wszystkie wierzchołki nie zostały już dopasowane. Jeśli tak, zwróć True.
        \item
        Dla każdego wierzchołka $v \in mozliwe\_dopasowania[i]$, jeśli $v$ $not$ $in$ $dopasowania$, przypisz $dopasowania[i] = v$ oraz wywołaj funkcję ponownie dla następnego wierzchołka $\in V(H)$ z przekazaną kopią. W przypadku wyniku True z tej funkcji, zwróć True, w przypadku False, $dopasowania[i] = null$  i przejdź do następnego kroku tej pętli.
        \item W przypadku niedopasowania po wszystkich iteracjach pętli, zwróć False.

    \end{enumerate}

    \subsubsection{Dowód poprawności}
    Najpierw zbadajmy, czy algorytm dobrze inicjalizuje $mozliwe\_dopasowania$. W tym celu rozbijmy wszystkie 3 warunki. Pierwszy warunek mówi o tym, że potencjalne dopasowanie $v$ dla wierzchołka $u$, musi mieć stopień co najmniej równy stopniowi wierzchołka $u$. Gdyby tak nie było, w grafie $G$ nie istniałaby co najmniej jedna krawędź wychodząca z $v$, która istniałaby w H i wychodziłaby z $u$, zatem $v$ nie mogłoby być dopasowaniem dla $u$.
    Drugi warunek mówi o tym, że liczba pętli dla $v$ musi być co najmniej równa liczbie pętli dla $u$. Idea jest taka sama jak warunku pierwszego, gdyby warunek nie był spełniony, nie istniałaby co najmniej jedna pętla da danego wierzchołka, a co za tym idzie, nie mógłby on być dopasowaniem dla $u$.

    Dalej w algorytmie, przechodzimy po kolei po wierzchołkach z H. Najpierw sprawdzamy, czy struktura się zgadza dla tych wierzchołków, do których znaleźliśmy już dopasowania. Jeśli choć 1 krawędź istniejąca w $H$ pomiędzy dwoma wierzchołkami nie będzie istnieć między ich dopasowaniami w $G$, algorytm wychodzi z tej ścieżki dopasowań i szuka innych, zatem działa poprawnie.

    Następnie sprawdzamy wszystkie z możliwych dopasowań dla danego wierzchołka, zatem sprawdzając tak wszystkie wierzchołki, mamy pewność, że przejdziemy po wszystkich możliwych permutacjach.

    \subsubsection{Złożoność obliczeniowa}
    Zauważmy, że inicjalizacja $mozliwe\_dopasowania$ w taki sposób, że dla każdego wierzchołka $u \in V(H)$ możliwym dopasowaniem są wszystkie $v \in V(G)$, to algorytm przejdzie po wszystkich poddrzewach, zatem w przypadku pesymistycznym do 1 wierzchołka wykona $n_G$ potencjalnych dopasowań, do drugiego $n_G - 1$, ..., a do $n_H$-tego, $(n_G - n_H + 1)$ dopasowań. Zatem mamy \[
                                                                                                                                                                                                                                                                                                                                                                                                \underbrace{(n_G)(n_G - 1)\dots(n_G - n_H + 1)}_{n_H\ \text{razy}} \le n_G^{n_H}
    \]
    W każdej takiej pętli wykonujemy sprawdzenie, czy struktura grafu się zgadza, (krok 4). Zauważmy, że wykonamy tam $i^2$ porównań, gdzie i to indeks aktualnie obliczanego wierzchołka. Wiemy że $i < n_H$, zatem możemy ograniczyć tę operację: $i^2 < n_H^2$. W sumie możemy stwierdzić, że złożoność tego algorytmu wyniesie $O(n_G^{n_H}n_H^2)$



    \pagebreak


% ---------------- MINIMALNE ROZSZERZENIE MULTIGRAFU ---------------- %

    \pagebreak

% ---------------- MINIMALNE ROZSZERZENIE ZAWIERAJĄCE M KOPII ---------------- %


    \section{Minimalne rozszerzenie multigrafu zawierającego m kopii podgrafu P}
    \label{sec:minimalne_rozszerzenie_m_kopii}

    \subsection{Motywacja i sformułowanie problemu}
    \label{subsec:motywacja_m_kopii}

    W poprzednich sekcjach zajmowaliśmy się problemem weryfikacji istnienia pojedynczego podgrafu izomorficznego z danym wzorcem. W praktycznych zastosowaniach często pojawia się jednak bardziej ogólne zagadnienie: jak minimalnie rozszerzyć graf $G$, aby zawierał on $m$ różnych kopii grafu wzorcowego $P$?

    Problem ten ma istotne zastosowania w dziedzinach takich jak:
    \begin{itemize}
        \item \textbf{Projektowanie sieci}: Zapewnienie redundancji przez istnienie wielu izomorficznych podsieci
        \item \textbf{Analiza struktur molekularnych}: Identyfikacja powtarzających się motywów strukturalnych
        \item \textbf{Analiza sieci społecznych}: Wykrywanie grup o podobnej strukturze relacji
        \item \textbf{Optymalizacja grafów}: Minimalne modyfikacje zachowujące pożądane właściwości strukturalne
    \end{itemize}

    \noindent\textbf{Formalne sformułowanie problemu:}

    \noindent\textit{Dane:}
    \begin{itemize}
        \item Multigraf skierowany $G = (V_G, E_G)$ o $n$ wierzchołkach (graf "duży")
        \item Multigraf skierowany $P = (V_P, E_P)$ o $k$ wierzchołkach, gdzie $k \leq n$ (graf "mały", wzorzec)
        \item Liczba naturalna $m \geq 1$ - wymagana liczba kopii
    \end{itemize}

    \noindent\textit{Zadanie:}
    \begin{itemize}
        \item Znaleźć minimalny zbiór krawędzi $E_{add}$ taki, że graf $G' = (V_G, E_G \cup E_{add})$ zawiera co najmniej $m$ podgrafów izomorficznych z $P$, przy czym każde dwa podgrafy różnią się przynajmniej jednym wierzchołkiem
    \end{itemize}

    \subsection{Definicje formalne}
    \label{subsec:definicje_m_kopii}

    \begin{definition}[Rozszerzenie multigrafu]
        \label{def:rozszerzenie}
        Niech $G = (V_G, E_G)$ i $G' = (V_{G'}, E_{G'})$ będą multigrafami. Mówimy, że $G'$ jest \textbf{rozszerzeniem} $G$, jeśli:
        \begin{enumerate}
            \item $V_G \subseteq V_{G'}$ (zbiór wierzchołków $G$ jest podzbiorem wierzchołków $G'$)
            \item $E_G \subseteq E_{G'}$ (zbiór krawędzi $G$ jest podzbiorem krawędzi $G'$)
        \end{enumerate}
    \end{definition}

    \noindent\textbf{Uzasadnienie:} Definicja jest naturalna i oparta na relacji inkluzji zbiorów. Zgodna z intuicją, że rozszerzenie grafu polega na dodaniu nowych wierzchołków i/lub krawędzi przy zachowaniu struktury oryginalnego grafu. Jest spójna z definicją podgrafu ($G$ jest podgrafem $G'$).

    \begin{definition}[Koszt rozszerzenia]
        \label{def:koszt_rozszerzenia}
        Niech $G = (V_G, E_G)$ i $G' = (V_{G'}, E_{G'})$ będą multigrafami takimi, że $G'$ jest rozszerzeniem $G$. \textbf{Kosztem rozszerzenia} $\gamma(G, G')$ nazywamy parę liczb naturalnych:
        \[
            \gamma(G, G') = (|V_{G'} \setminus V_G|, |E_{G'} \setminus E_G|)
        \]
        gdzie:
        \begin{itemize}
            \item $|V_{G'} \setminus V_G|$ to liczba dodanych wierzchołków
            \item $|E_{G'} \setminus E_G|$ to liczba dodanych krawędzi
        \end{itemize}
    \end{definition}

    \noindent\textbf{Uzasadnienie:} Koszt uwzględnia dwie podstawowe operacje rozszerzania grafu. W kontekście naszego algorytmu skupiamy się głównie na dodawaniu krawędzi, zakładając stałą liczbę wierzchołków ($V_G = V_{G'}$).

    \begin{definition}[Porządek leksykograficzny na kosztach]
        \label{def:porzadek_kosztow}
        Dla dwóch kosztów $(v_1, e_1)$ i $(v_2, e_2)$ definiujemy porządek leksykograficzny:
        \[
            (v_1, e_1) < (v_2, e_2) \iff v_1 < v_2 \lor (v_1 = v_2 \land e_1 < e_2)
        \]
    \end{definition}

    \noindent\textbf{Uzasadnienie:} Porządek leksykograficzny priorytetyzuje minimalizację liczby dodanych wierzchołków, a następnie krawędzi.

    \begin{definition}[Osadzenie k-wierzchołkowe]
        \label{def:osadzenie_k}
        \textbf{Osadzenie k-wierzchołkowe} grafu $P$ w grafie $G$ definiujemy przez parę $(C, \pi)$, gdzie:
        \begin{enumerate}
            \item $C \subseteq V_G$ jest \textbf{k-kombinacją} - podzbiorem wierzchołków takim, że $|C| = k = |V_P|$
            \item $\pi: V_P \to C$ jest \textbf{k-permutacją} - bijekcją mapującą wierzchołki $P$ na wierzchołki $C$
        \end{enumerate}
        Para $(C, \pi)$ definiuje potencjalne osadzenie $P$ w $G$ poprzez podgraf indukowany przez $C$ z odpowiednim mapowaniem wierzchołków.
    \end{definition}

    \noindent\textbf{Uzasadnienie:} Formalizuje procedurę przeszukiwania przestrzeni możliwych osadzeń. Bezpośrednio odpowiada implementacji (kombinacje i permutacje w kodzie). Liczba możliwych osadzeń wynosi $\binom{n}{k} \times k!$.

    \begin{definition}[Brakujące krawędzie dla osadzenia]
        \label{def:brakujace_krawedzie}
        Niech $G = (V_G, E_G)$ i $P = (V_P, E_P)$ będą multigrafami, gdzie $|V_P| = k \leq |V_G| = n$. Niech $(C, \pi)$ będzie osadzeniem k-wierzchołkowym $P$ w $G$. \textbf{Zbiorem brakujących krawędzi} dla osadzenia $(C, \pi)$ nazywamy multizbiór:
        \[
            \Delta((C, \pi), G, P) = \{(\pi(u), \pi(v)) : u, v \in V_P\}
        \]
        z krotnościami:
        \[
            \text{mult}_\Delta(\pi(u), \pi(v)) = \max(0, A_P[u][v] - A_G[\pi(u)][\pi(v)])
        \]
        gdzie $A_P$, $A_G$ są macierzami sąsiedztwa odpowiednio grafów $P$ i $G$.
    \end{definition}

    \noindent\textbf{Uzasadnienie:} Umożliwia kwantyfikację odległości między potencjalnym osadzeniem a rzeczywistym izomorfizmem. Stanowi podstawę algorytmu konstrukcji minimalnego rozszerzenia. Uwzględnia krotności krawędzi (multigrafowość).

    \begin{definition}[Minimalne rozszerzenie zawierające m kopii podgrafu P]
        \label{def:minimalne_rozszerzenie_m}
        Niech $G = (V_G, E_G)$ i $P = (V_P, E_P)$ będą multigrafami, gdzie $|V_P| \leq |V_G|$, oraz niech $m \geq 1$ będzie liczbą naturalną. \textbf{Minimalnym rozszerzeniem} $G$ zawierającym $m$ kopii $P$ nazywamy multigraf $G' = (V_{G'}, E_{G'})$ spełniający następujące warunki:

        \begin{enumerate}
            \item $G'$ jest rozszerzeniem $G$ (tj. $V_G \subseteq V_{G'}$, $E_G \subseteq E_{G'}$)
            \item $G'$ zawiera co najmniej $m$ podgrafów izomorficznych z $P$, przy czym każde dwa podgrafy różnią się przynajmniej jednym wierzchołkiem (tzn. dla dowolnych dwóch podgrafów $H_i$, $H_j$ zachodzi $V_{H_i} \neq V_{H_j}$)
            \item Koszt rozszerzenia $\gamma(G, G')$ jest minimalny w sensie porządku leksykograficznego wśród wszystkich rozszerzeń spełniających warunki 1 i 2
        \end{enumerate}
    \end{definition}

    \noindent\textbf{Uzasadnienie:} Warunek $V_{H_i} \neq V_{H_j}$ zapewnia, że kopie są rzeczywiście różne (nie są tym samym podgrafem), ale dopuszcza częściowe pokrywanie się zbiorów wierzchołków. Jest to słabsze wymaganie niż pełna rozłączność wierzchołkowa, ale wystarczające do sensownego policzenia $m$ różnych kopii grafu $P$. W implementacji zakładamy $V_G = V_{G'}$ (nie dodajemy wierzchołków), więc minimalizujemy tylko liczbę dodanych krawędzi. Definicja jest operacyjna i pozwala na konstrukcję algorytmów.

    \subsection{Algorytmy pomocnicze}
    \label{subsec:algorytmy_pomocnicze}

    Algorytm główny wykorzystuje trzy fundamentalne algorytmy kombinatoryczne: generowanie k-kombinacji, generowanie permutacji oraz generowanie produktu kartezjańskiego (m-krotek). W tej sekcji przedstawiamy szczegółowe opisy tych algorytmów wraz z dowodami poprawności i analizą złożoności.

    \subsubsection{Algorytm generowania k-kombinacji}
    \label{subsubsec:kombinacje}

    \textbf{Problem:} Dla danego zbioru $n$ elementów wygenerować wszystkie jego $k$-elementowe podzbiory (kombinacje).

    \textbf{Właściwości:}
    \begin{itemize}
        \item Liczba k-kombinacji ze zbioru n-elementowego: $\binom{n}{k} = \frac{n!}{k!(n-k)!}$
        \item Kombinacje są nieuporządkowane (zbiory, nie ciągi)
        \item Kolejność generowania: leksykograficzna według indeksów
    \end{itemize}

    \begin{algorithm}[H]
        \caption{GenerateCombinations($items$, $k$)}
        \label{alg:combinations}
        \begin{algorithmic}[1]
            \Require $items$ - lista n elementów, $k$ - rozmiar kombinacji
            \Ensure Wszystkie k-kombinacje elementów z $items$
            \If{$k = 0$}
                \State \textbf{yield} $[\,]$ \Comment{Pusta kombinacja}
                \State \Return
            \EndIf
            \If{$k > n$}
                \State \Return \Comment{Brak kombinacji}
            \EndIf
            \State $c \gets [0, 1, 2, \ldots, k-1]$ \Comment{Początkowa kombinacja indeksów}
            \While{\textbf{true}}
                \State \textbf{yield} $[items[c[0]], items[c[1]], \ldots, items[c[k-1]]]$
                \State $i \gets k - 1$
                \While{$i \geq 0$ \textbf{and} $c[i] = n - k + i$}
                    \State $i \gets i - 1$
                \EndWhile
                \If{$i < 0$}
                    \State \textbf{break} \Comment{Wszystkie kombinacje wygenerowane}
                \EndIf
                \State $c[i] \gets c[i] + 1$
                \For{$j \gets i + 1$ \textbf{to} $k - 1$}
                    \State $c[j] \gets c[j-1] + 1$
                \EndFor
            \EndWhile
        \end{algorithmic}
    \end{algorithm}

    \textbf{Dowód poprawności:}

    \begin{proof}
        Algorytm reprezentuje kombinacje jako rosnące ciągi indeksów $c[0] < c[1] < \ldots < c[k-1]$, gdzie $0 \leq c[i] \leq n-1$.

        \textbf{Niezmiennik:} W każdej iteracji głównej pętli, tablica $c$ reprezentuje poprawną k-kombinację (ściśle rosnący ciąg indeksów).

        \textbf{Kompletność:} Algorytm generuje wszystkie kombinacje, ponieważ:
        \begin{enumerate}
            \item Rozpoczyna od najmniejszej kombinacji $[0, 1, \ldots, k-1]$
            \item W każdej iteracji znajduje najbardziej prawy indeks $i$, który można zwiększyć (linie 10-12)
            \item Zwiększa $c[i]$ i ustawia następne indeksy jako kolejne liczby (linie 16-18)
            \item To jest standardowy algorytm generowania kombinacji w porządku leksykograficznym
            \item Kończy gdy nie można zwiększyć żadnego indeksu (największa kombinacja $[n-k, n-k+1, \ldots, n-1]$)
        \end{enumerate}

        \textbf{Brak duplikatów:} Każda kombinacja jest unikalna, ponieważ algorytm ściśle następuje porządek leksykograficzny i nigdy nie cofa się do wcześniej wygenerowanych kombinacji.

        \textbf{Poprawność struktury:} Niezmiennik $c[0] < c[1] < \ldots < c[k-1]$ jest zachowany w każdej iteracji przez konstrukcję algorytmu (linie 16-18).
    \end{proof}

    \textbf{Złożoność obliczeniowa:}
    \begin{itemize}
        \item \textbf{Liczba iteracji:} $\binom{n}{k}$ (liczba kombinacji do wygenerowania)
        \item \textbf{Koszt jednej iteracji:} $O(k)$ - wyprodukowanie kombinacji i znalezienie indeksu do zwiększenia
        \item \textbf{Złożoność czasowa całkowita:} $O\left(\binom{n}{k} \cdot k\right)$
        \item \textbf{Złożoność pamięciowa:} $O(k)$ - przechowywanie tablicy indeksów
    \end{itemize}

    \subsubsection{Algorytm generowania permutacji}
    \label{subsubsec:permutacje}

    \textbf{Problem:} Dla danego zbioru $n$ elementów wygenerować wszystkie jego permutacje (uporządkowania).

    \textbf{Właściwości:}
    \begin{itemize}
        \item Liczba permutacji zbioru n-elementowego: $n!$
        \item Wykorzystujemy algorytm Heapa - minimalizuje liczbę zamian elementów
        \item Generowanie w miejscu (in-place)
    \end{itemize}

    \begin{algorithm}[H]
        \caption{GeneratePermutations($items$)}
        \label{alg:permutations}
        \begin{algorithmic}[1]
            \Require $items$ - lista n elementów
            \Ensure Wszystkie permutacje elementów z $items$
            \State $n \gets |items|$
            \If{$n \leq 1$}
                \State \textbf{yield} $items$
                \State \Return
            \EndIf
            \State $a \gets$ kopia $items$ \Comment{Praca na kopii}
            \State $c \gets [0, 0, \ldots, 0]$ \Comment{Liczniki dla algorytmu Heapa, długość n}
            \State \textbf{yield} kopia $a$ \Comment{Pierwsza permutacja}
            \State $i \gets 0$
            \While{$i < n$}
                \If{$c[i] < i$}
                    \If{$i$ mod $2 = 0$}
                        \State swap($a[0]$, $a[i]$)
                    \Else
                        \State swap($a[c[i]]$, $a[i]$)
                    \EndIf
                    \State \textbf{yield} kopia $a$
                    \State $c[i] \gets c[i] + 1$
                    \State $i \gets 0$
                \Else
                    \State $c[i] \gets 0$
                    \State $i \gets i + 1$
                \EndIf
            \EndWhile
        \end{algorithmic}
    \end{algorithm}

    \textbf{Dowód poprawności:}

    \begin{proof}
        Algorytm Heapa wykorzystuje nierekurencyjną implementację z licznikami $c[i]$ reprezentującymi stan rekurencji.

        \textbf{Kompletność:} Algorytm generuje dokładnie $n!$ permutacji, ponieważ:
        \begin{enumerate}
            \item Dla każdego $i$ wartość $c[i]$ przyjmuje wartości od $0$ do $i-1$, co daje $i$ możliwości
            \item Całkowita liczba stanów: $1 \cdot 2 \cdot 3 \cdots n = n!$
            \item Każdemu stanowi odpowiada unikalna permutacja
        \end{enumerate}

        \textbf{Brak duplikatów:} Każda kombinacja wartości liczników $c$ występuje dokładnie raz, co gwarantuje unikalność permutacji.

        \textbf{Minimalna liczba zamian:} Algorytm Heapa minimalizuje liczbę zamian - średnio około $1$ zamiany na permutację (znacznie lepiej niż $O(n)$ w algorytmach naiwnych).
    \end{proof}

    \textbf{Złożoność obliczeniowa:}
    \begin{itemize}
        \item \textbf{Liczba iteracji:} $n!$ (liczba permutacji)
        \item \textbf{Koszt jednej iteracji:} $O(1)$ - zamiany elementów i kopiowanie
        \item \textbf{Koszt kopiowania permutacji:} $O(n)$ na permutację
        \item \textbf{Złożoność czasowa całkowita:} $O(n! \cdot n)$
        \item \textbf{Złożoność pamięciowa:} $O(n)$ - tablice $a$ i $c$
    \end{itemize}

    \subsubsection{Algorytm generowania produktu kartezjańskiego}
    \label{subsubsec:produkt_kartezjanski}

    \textbf{Problem:} Dla danego zbioru $items$ i liczby $m$ wygenerować wszystkie $m$-krotki (sekwencje długości $m$) złożone z elementów $items$ (z powtórzeniami).

    \textbf{Właściwości:}
    \begin{itemize}
        \item Liczba $m$-krotek ze zbioru k-elementowego: $k^m$
        \item Odpowiada produktowi kartezjańskiemu $items^m = items \times items \times \cdots \times items$
        \item Generowanie w porządku leksykograficznym
    \end{itemize}

    \begin{algorithm}[H]
        \caption{ProductSequences($items$, $m$)}
        \label{alg:product}
        \begin{algorithmic}[1]
            \Require $items$ - lista k elementów, $m$ - długość sekwencji
            \Ensure Wszystkie m-krotki elementów z $items$
            \State $k \gets |items|$
            \If{$m = 0$}
                \State \textbf{yield} $[\,]$
                \State \Return
            \EndIf
            \If{$k = 0$}
                \State \Return \Comment{Brak sekwencji}
            \EndIf
            \State $digits \gets [0, 0, \ldots, 0]$ \Comment{Tablica m cyfr w systemie bazy k}
            \While{\textbf{true}}
                \State \textbf{yield} $[items[digits[0]], items[digits[1]], \ldots, items[digits[m-1]]]$
                \State $i \gets 0$ \Comment{Inkrementacja licznika w systemie bazy k}
                \While{$i < m$}
                    \If{$digits[i] + 1 < k$}
                        \State $digits[i] \gets digits[i] + 1$
                        \State \textbf{break}
                    \Else
                        \State $digits[i] \gets 0$
                        \State $i \gets i + 1$
                    \EndIf
                \EndWhile
                \If{$i = m$}
                    \State \textbf{break} \Comment{Przepełnienie - wszystkie sekwencje wygenerowane}
                \EndIf
            \EndWhile
        \end{algorithmic}
    \end{algorithm}

    \textbf{Dowód poprawności:}

    \begin{proof}
        Algorytm traktuje sekwencje jako liczby w systemie pozycyjnym o podstawie $k$.

        \textbf{Reprezentacja:} Każda $m$-krotka odpowiada liczbie w systemie bazy $k$:
        \[
            \text{number} = digits[0] + digits[1] \cdot k + digits[2] \cdot k^2 + \cdots + digits[m-1] \cdot k^{m-1}
        \]
        gdzie $0 \leq digits[i] < k$.

        \textbf{Kompletność:} Algorytm generuje wszystkie liczby od $0$ do $k^m - 1$:
        \begin{enumerate}
            \item Rozpoczyna od $[0, 0, \ldots, 0]$ (liczba 0)
            \item W każdej iteracji inkrementuje liczbę o 1 (linie 13-20)
            \item Kończy przy przepełnieniu (liczba $k^m$, co odpowiada stanowi po ostatniej sekwencji)
            \item Każdej liczbie odpowiada unikalna $m$-krotka
        \end{enumerate}

        \textbf{Brak duplikatów:} Ponieważ algorytm ściśle liczy od 0 do $k^m - 1$, każda sekwencja jest wygenerowana dokładnie raz.

        \textbf{Poprawność inkrementacji:} Linie 13-20 implementują standardową inkrementację w systemie pozycyjnym z propagacją przeniesienia (carry).
    \end{proof}

    \textbf{Złożoność obliczeniowa:}
    \begin{itemize}
        \item \textbf{Liczba iteracji:} $k^m$ (liczba $m$-krotek)
        \item \textbf{Koszt jednej iteracji:} $O(m)$ w najgorszym przypadku (propagacja przeniesienia przez wszystkie pozycje)
        \item \textbf{Średni koszt iteracji:} $O(1)$ (przeniesienie rzadko propaguje daleko)
        \item \textbf{Złożoność czasowa całkowita:} $O(k^m \cdot m)$ (pesymistyczna), $O(k^m)$ (średnia)
        \item \textbf{Złożoność pamięciowa:} $O(m)$ - tablica $digits$
    \end{itemize}

    \textbf{Porównanie z innymi metodami:}
    \begin{itemize}
        \item \textbf{Rekurencja:} Intuicyjna, ale wymaga $O(m)$ stosu dla każdej sekwencji
        \item \textbf{Podejście iteracyjne:} Używane tutaj - wydajniejsze pamięciowo, $O(m)$ bez nadmiarowych wywołań
    \end{itemize}

    \subsection{Algorytm dokładny}
    \label{subsec:algorytm_dokladny_m}

    \subsubsection{Przegląd algorytmu}
    \label{subsubsec:przeglad_algorytmu}

    Algorytm oparty jest na pełnym przeszukiwaniu przestrzeni rozwiązań. Strategia polega na:
    \begin{enumerate}
        \item Wygenerowaniu wszystkich możliwych osadzeń grafu $P$ w grafie $G$
        \item Obliczeniu brakujących krawędzi dla każdego osadzenia
        \item Rozważeniu wszystkich możliwych m-krotnych osadzeń dla $m$ kopii
        \item Wybraniu osadzenia minimalizującego liczbę dodanych krawędzi
    \end{enumerate}

    Algorytm składa się z dwóch głównych faz:
    \begin{itemize}
        \item \textbf{Faza 1:} Generowanie osadzeń i macierzy brakujących krawędzi
        \item \textbf{Faza 2:} Znajdowanie minimalnego rozszerzenia dla $m$ kopii
    \end{itemize}

    \subsubsection{Szczegółowy opis algorytmu}
    \label{subsubsec:szczegolowy_opis}

    \textbf{Faza 1: Generowanie osadzeń i macierzy brakujących krawędzi}

    \noindent\textbf{Krok 1: Generowanie k-kombinacji wierzchołków G}

    Dla grafu $G$ o $n$ wierzchołkach generujemy wszystkie możliwe $k$-kombinacje wierzchołków, gdzie $k = |V_P|$. Każda kombinacja $C_j \subseteq V_G$ reprezentuje potencjalny zbiór wierzchołków, na które można zmapować graf $P$.

    \begin{itemize}
        \item \textit{Wejście:} $G = (V_G, E_G)$, $|V_G| = n$, $k = |V_P|$
        \item \textit{Wyjście:} Zbiór wszystkich $k$-kombinacji $\{C_1, C_2, \ldots, C_N\}$, gdzie $N = \binom{n}{k}$
        \item \textit{Implementacja:} Algorytm \ref{alg:combinations} (GenerateCombinations) - szczegóły w sekcji \ref{subsubsec:kombinacje}
        \item \textit{Złożoność:} $O\left(\binom{n}{k} \times k\right)$
    \end{itemize}

    \noindent\textbf{Krok 2: Generowanie permutacji wierzchołków P}

    Dla grafu $P$ o $k$ wierzchołkach generujemy wszystkie możliwe permutacje. Każda permutacja $\pi_i: V_P \to V_P$ reprezentuje potencjalne uporządkowane mapowanie wierzchołków $P$ na wierzchołki kombinacji $C_j$.

    \begin{itemize}
        \item \textit{Wejście:} $P = (V_P, E_P)$, $|V_P| = k$
        \item \textit{Wyjście:} Zbiór wszystkich permutacji $\{\pi_1, \pi_2, \ldots, \pi_M\}$, gdzie $M = k!$
        \item \textit{Implementacja:} Algorytm \ref{alg:permutations} (GeneratePermutations, algorytm Heapa) - szczegóły w sekcji \ref{subsubsec:permutacje}
        \item \textit{Złożoność:} $O(k! \times k)$
    \end{itemize}

    \noindent\textbf{Krok 3: Obliczanie brakujących krawędzi}

    Dla każdej pary $(C_j, \pi_i)$ obliczamy listę krawędzi, które należy dodać do $G$, aby podgraf indukowany przez $C_j$ z mapowaniem $\pi_i$ był izomorficzny z $P$.

    Dla każdej pary wierzchołków $(u, v) \in V_P \times V_P$:
    \begin{itemize}
        \item Obliczamy obrazy: $u' = C_j[\pi_i(u)]$, $v' = C_j[\pi_i(v)]$
        \item Liczba krawędzi w $P$: $e_P = A_P[\pi_i(u)][\pi_i(v)]$
        \item Liczba krawędzi w $G$: $e_G = A_G[u'][v']$
        \item Brakujące krawędzie: $\Delta = \max(0, e_P - e_G)$
        \item Dodajemy $\Delta$ kopii krawędzi $(u', v')$ do listy brakujących krawędzi
    \end{itemize}

    Wynik zapisujemy w macierzy $\text{missingEdgesMatrix}[i][j]$ jako listę brakujących krawędzi dla permutacji $i$ i kombinacji $j$.

    \begin{itemize}
        \item \textit{Złożoność pojedynczego obliczenia:} $O(k^2)$
        \item \textit{Całkowita złożoność:} $O\left(\binom{n}{k} \times k! \times k^2\right)$
        \item \textit{Pamięć:} $O\left(\binom{n}{k} \times k! \times k^2\right)$ w najgorszym przypadku
    \end{itemize}

    \textbf{Faza 2: Znajdowanie minimalnego rozszerzenia dla m kopii}

    \noindent\textbf{Krok 4: Generowanie m-kombinacji osadzeń}

    \noindent\textbf{Krok 4: Generowanie m-kombinacji osadzeń}

    Generujemy wszystkie możliwe sposoby wyboru $m$ różnych kombinacji wierzchołków spośród $N = \binom{n}{k}$ dostępnych kombinacji. Każda taka $m$-kombinacja reprezentuje wybór $m$ różnych podzbiorów dla $m$ kopii grafu $P$. Ponieważ są to kombinacje (a nie permutacje z powtórzeniami), każde dwa podzbiory w wybranej $m$-krotce są różne, co zapewnia, że odpowiadające im kopie różnią się przynajmniej jednym wierzchołkiem.

    \begin{itemize}
        \item \textit{Liczba $m$-kombinacji:} $\binom{\binom{n}{k}}{m}$
        \item \textit{Złożoność:} $O\left(\binom{\binom{n}{k}}{m} \times m\right)$
    \end{itemize}

    \noindent\textbf{Krok 5: Generowanie m-krotek permutacji}

    Dla każdej $m$-kombinacji podzbiorów, generujemy wszystkie możliwe $m$-krotki permutacji. Każda $m$-krotka $(i_1, i_2, \ldots, i_m)$ określa, jaką permutację stosujemy dla każdej z $m$ kopii.

    \begin{itemize}
        \item \textit{Liczba $m$-krotek:} $(k!)^m$
        \item \textit{Implementacja:} Algorytm \ref{alg:product} (ProductSequences) - szczegóły w sekcji \ref{subsubsec:produkt_kartezjanski}
        \item \textit{Złożoność:} $O((k!)^m \times m)$
    \end{itemize}

    \noindent\textbf{Krok 6: Obliczanie unii zbiorów krawędzi}

    Dla każdej konfiguracji ($m$-kombinacja podzbiorów, $m$-krotka permutacji) obliczamy minimalny zbiór krawędzi potrzebny do stworzenia $m$ kopii grafu $P$.

    Kluczowa obserwacja: jeśli wielokrotne kopie wymagają tej samej krawędzi $(u, v)$ z krotnościami $k_1, k_2, \ldots, k_m$, wystarczy dodać $\max(k_1, k_2, \ldots, k_m)$ kopii tej krawędzi, ponieważ krawędzie mogą być współdzielone między kopiami.

    Algorytm:
    \begin{enumerate}
        \item Inicjalizujemy mapę częstości: \texttt{edgeFrequencyMap = \{\}}
        \item Dla każdej z $m$ kopii ($t = 1, \ldots, m$):
        \begin{enumerate}
            \item Pobieramy brakujące krawędzie dla kopii $t$
            \item Tworzymy lokalną mapę częstości krawędzi dla tej kopii
            \item Aktualizujemy globalną mapę: dla każdej krawędzi $e$, ustawiamy \\
            \texttt{edgeFrequencyMap[e] = max(edgeFrequencyMap[e], localFrequency[e])}
        \end{enumerate}
        \item Konwertujemy mapę częstości na listę krawędzi
        \item Jeśli rozmiar listy jest mniejszy niż dotychczasowe minimum, aktualizujemy rozwiązanie
    \end{enumerate}

    \begin{itemize}
        \item \textit{Złożoność:} $O\left(\binom{\binom{n}{k}}{m} \times (k!)^m \times m \times k^2\right)$
    \end{itemize}

    \subsubsection{Pseudokod algorytmu}
    \label{subsubsec:pseudokod}

    Algorytm został podzielony na dwie części dla lepszej czytelności: Fazę 1 (generowanie osadzeń i obliczanie brakujących krawędzi) oraz Fazę 2 (znajdowanie minimalnego rozszerzenia dla $m$ kopii).

    \begin{algorithm}[H]
        \caption{MinimalGraphExtension - Faza 1: Generowanie osadzeń}
        \label{alg:minimal_extension_phase1}
        \begin{algorithmic}[1]
            \Require $G = (V_G, E_G)$ - multigraf "duży", $|V_G| = n$
            \Require $P = (V_P, E_P)$ - multigraf "mały", $|V_P| = k$
            \Ensure Macierz $missingEdgesMatrix$ z brakującymi krawędziami
            \State \textit{// Generuj k-kombinacje wierzchołków G}
            \State $combinations \gets \text{GenerateCombinations}(V_G, k)$
            \State $indexToSubset \gets \text{IndexMap}(combinations)$
            \State \textit{// Generuj permutacje wierzchołków P}
            \State $permutations \gets \text{GeneratePermutations}(V_P)$
            \State $indexToPermutation \gets \text{IndexMap}(permutations)$
            \State $missingEdgesMatrix \gets \text{Array}[|indexToPermutation|][|indexToSubset|]$
            \For{$i \gets 0$ \textbf{to} $|indexToPermutation| - 1$}
                \For{$j \gets 0$ \textbf{to} $|indexToSubset| - 1$}
                    \State $\pi \gets indexToPermutation[i]$; $C \gets indexToSubset[j]$
                    \State $missingEdgesMatrix[i][j] \gets [\,]$
                    \For{$u \gets 0$ \textbf{to} $k-1$}
                        \For{$v \gets 0$ \textbf{to} $k-1$}
                            \State $u' \gets C[\pi[u]]$; $v' \gets C[\pi[v]]$
                            \State $\Delta \gets \max(0, A_P[\pi[u]][\pi[v]] - A_G[u'][v'])$
                            \For{$t \gets 0$ \textbf{to} $\Delta - 1$}
                                \State $missingEdgesMatrix[i][j].\text{append}((u', v'))$
                            \EndFor
                        \EndFor
                    \EndFor
                \EndFor
            \EndFor
            \State \Return $missingEdgesMatrix$, $indexToSubset$, $indexToPermutation$
        \end{algorithmic}
    \end{algorithm}

    \begin{algorithm}[H]
        \caption{MinimalGraphExtension - Faza 2: Znajdowanie minimalnego rozszerzenia}
        \label{alg:minimal_extension_phase2}
        \begin{algorithmic}[1]
            \Require $missingEdgesMatrix$, $indexToSubset$, $indexToPermutation$, $m$
            \Ensure Lista krawędzi do dodania do $G$
            \State $mCombinations \gets \text{GenerateCombinations}(indexToSubset.keys, m)$
            \State $minimalEdges \gets \text{null}$; $minimalSize \gets \infty$
            \For{\textbf{each} $\{j_1, \ldots, j_m\}$ \textbf{in} $mCombinations$}
                \For{\textbf{each} $(i_1, \ldots, i_m)$ \textbf{in} $\text{ProductSeq}(indexToPermutation.keys, m)$}
                    \State $edgeFreqMap \gets \{\}$
                    \For{$t \gets 0$ \textbf{to} $m-1$}
                        \State $missingEdges \gets missingEdgesMatrix[i_t][j_t]$
                        \State $localFreq \gets \{\}$
                        \For{\textbf{each} $e$ \textbf{in} $missingEdges$}
                            \State $localFreq[e] \gets localFreq[e] + 1$
                        \EndFor
                        \For{\textbf{each} $(e, freq)$ \textbf{in} $localFreq$}
                            \State $edgeFreqMap[e] \gets \max(edgeFreqMap[e], freq)$
                        \EndFor
                    \EndFor
                    \State $addedEdges \gets [\,]$
                    \For{\textbf{each} $(e, freq)$ \textbf{in} $edgeFreqMap$}
                        \For{$t \gets 0$ \textbf{to} $freq - 1$}
                            \State $addedEdges.\text{append}(e)$
                        \EndFor
                    \EndFor
                    \If{$|addedEdges| < minimalSize$}
                        \State $minimalSize \gets |addedEdges|$; $minimalEdges \gets addedEdges$
                    \EndIf
                \EndFor
            \EndFor
            \State \Return $minimalEdges$
        \end{algorithmic}
    \end{algorithm}

    \subsection{Dowód poprawności algorytmu}
    \label{subsec:dowod_poprawnosci}

    \begin{theorem}[Poprawność algorytmu MinimalGraphExtension]
        \label{thm:poprawnosc}
        Algorytm MinimalGraphExtension zwraca minimalną listę krawędzi do dodania do $G$, aby zawierał $m$ różnych kopii $P$ (tzn. kopii różniących się przynajmniej jednym wierzchołkiem).
    \end{theorem}

    \begin{proof}
        Dowód podzielimy na trzy części: kompletność, poprawność i minimalność.

        \textbf{Część 1: Kompletność (algorytm znajduje rozwiązanie, jeśli istnieje)}

        Załóżmy, że istnieje rozszerzenie $G'$ grafu $G$ zawierające $m$ różnych kopii $P$ (tzn. kopii różniących się przynajmniej jednym wierzchołkiem), osiągnięte przez dodanie zbioru krawędzi $E_{add}$.

        \begin{enumerate}
            \item Dla każdej z $m$ kopii $P$ w $G'$ istnieje:
            \begin{itemize}
                \item $k$-kombinacja wierzchołków $C_t \subseteq V_G$ ($t = 1, \ldots, m$)
                \item Permutacja $\pi_t: V_P \to V_P$
                \item Takie że podgraf $G'$ indukowany przez $C_t$ z odpowiednim mapowaniem jest izomorficzny z $P$
            \end{itemize}

            \item Kombinacje $C_t$ są różne ($C_i \neq C_j$ dla $i \neq j$), co zapewnia, że kopie różnią się przynajmniej jednym wierzchołkiem

            \item Algorytm generuje wszystkie możliwe $m$-kombinacje $k$-podzbiorów (linia 3 Fazy 2), co gwarantuje, że wybranych $m$ podzbiorów jest parami różnych

            \item Dla każdej $m$-kombinacji, algorytm generuje wszystkie możliwe $m$-krotki permutacji (linia 4 Fazy 2)

            \item Zatem algorytm rozważy kombinację $\{C_1, \ldots, C_m\}$ i krotkę permutacji $(\pi_1, \ldots, \pi_m)$ odpowiadającą rzeczywistemu rozwiązaniu

            \item Dla tej kombinacji i krotki permutacji, algorytm obliczy dokładnie te same krawędzie, które są w $E_{add}$ (linie 5-16 Fazy 2)
        \end{enumerate}

        \textbf{Część 2: Poprawność (dodane krawędzie są wystarczające)}

        Dla dowolnej $m$-kombinacji podzbiorów i $m$-krotki permutacji rozważanej przez algorytm:

        \begin{enumerate}
            \item Dla każdej z $m$ kopii (linie 33-42):
            \begin{itemize}
                \item Algorytm oblicza brakujące krawędzie zapisane wcześniej w $missingEdgesMatrix$
                \item Te krawędzie są dokładnie tymi, których brakuje do stworzenia izomorfizmu (z Fazy 1)
            \end{itemize}

            \item Operacja maksimum na krotnościach (linia 41) zapewnia:
            \begin{itemize}
                \item Jeśli wielokrotne kopie potrzebują tej samej krawędzi $(u,v)$ z krotnościami $k_1, k_2, \ldots$, dodajemy $\max(k_1, k_2, \ldots)$ kopii
                \item To jest \textit{wystarczające}, bo krawędzie mogą być współdzielone między kopiami
                \item To jest \textit{konieczne}, bo każda kopia wymaga odpowiedniej krotności
            \end{itemize}

            \item Po dodaniu krawędzi z $addedEdges$ do $G$:
            \begin{itemize}
                \item Każda z $m$ kopii ma wystarczającą liczbę krawędzi między każdą parą wierzchołków
                \item Każda kopia jest izomorficzna z $P$
            \end{itemize}
        \end{enumerate}

        \textbf{Część 3: Minimalność (algorytm znajduje minimum)}

        \begin{enumerate}
            \item Algorytm przeszukuje wszystkie możliwe sposoby osadzenia $m$ kopii $P$ w $G$ (linie 30-31)

            \item Dla każdego sposobu oblicza minimalną liczbę krawędzi potrzebnych do realizacji tego osadzenia (linie 33-48)

            \item Wybiera osadzenie wymagające najmniejszej liczby krawędzi (linie 49-52)

            \item Nie istnieje sposób osadzenia $m$ kopii $P$ w $G$ wymagający mniej krawędzi, bo wszystkie sposoby zostały rozważone
        \end{enumerate}

        Zatem algorytm jest poprawny - zwraca minimalną liczbę krawędzi wystarczających do stworzenia $m$ różnych kopii $P$ w $G$ (różniących się przynajmniej jednym wierzchołkiem).
    \end{proof}

    \subsection{Analiza złożoności obliczeniowej}
    \label{subsec:zlozonosc_obliczeniowa}

    \subsubsection{Złożoność czasowa}
    \label{subsubsec:zlozonosc_czasowa}

    Oznaczmy:
    \begin{itemize}
        \item $n = |V_G|$ - liczba wierzchołków dużego grafu $G$
        \item $k = |V_P|$ - liczba wierzchołków małego grafu $P$
        \item $m$ - liczba wymaganych kopii $P$ w $G$
    \end{itemize}

    \textbf{Rozbicie na fazy:}

    \begin{enumerate}
        \item \textbf{Faza 1a - Generowanie kombinacji:} $O\left(\binom{n}{k} \times k\right)$
        \begin{itemize}
            \item Liczba kombinacji: $\binom{n}{k}$
            \item Koszt generowania jednej kombinacji: $O(k)$
        \end{itemize}

        \item \textbf{Faza 1b - Generowanie permutacji:} $O(k! \times k)$
        \begin{itemize}
            \item Liczba permutacji: $k!$
            \item Koszt generowania jednej permutacji: $O(k)$
        \end{itemize}

        \item \textbf{Faza 1c - Obliczanie missingEdgesMatrix:} $O\left(\binom{n}{k} \times k! \times k^2\right)$
        \begin{itemize}
            \item Dla każdej z $\binom{n}{k}$ kombinacji
            \item Dla każdej z $k!$ permutacji
            \item Porównanie $k^2$ par krawędzi
        \end{itemize}

        \item \textbf{Faza 2a - Generowanie m-kombinacji osadzeń:} $O\left(\binom{\binom{n}{k}}{m} \times m\right)$
        \begin{itemize}
            \item Liczba $m$-kombinacji: $\binom{\binom{n}{k}}{m}$
        \end{itemize}

        \item \textbf{Faza 2b - Główna pętla przeszukiwania:}
        \[
            O\left(\binom{\binom{n}{k}}{m} \times (k!)^m \times m \times k^2\right)
        \]
        \begin{itemize}
            \item Dla każdej $m$-kombinacji podzbiorów: $\binom{\binom{n}{k}}{m}$
            \item Dla każdej $m$-krotki permutacji: $(k!)^m$
            \item Dla każdej z $m$ kopii: $m$
            \item Obliczanie częstości krawędzi: $O(k^2)$ dla jednej kopii
        \end{itemize}
    \end{enumerate}

    \textbf{Całkowita złożoność czasowa:}
    \[
        T(n, k, m) = O\left(\binom{n}{k} \times k! \times k^2\right) + O\left(\binom{\binom{n}{k}}{m} \times (k!)^m \times m \times k^2\right)
    \]

    \textbf{Dominujący składnik} dla małych $m$ (gdy $m \ll \binom{n}{k}$):
    \[
        T(n, k, m) = O\left(\binom{n}{k} \times k! \times k^2\right)
    \]

    \textbf{Dominujący składnik} dla większych $m$:
    \[
        T(n, k, m) = O\left(\binom{\binom{n}{k}}{m} \times (k!)^m \times m \times k^2\right)
    \]

    \textbf{Oszacowania asymptotyczne:}
    \begin{itemize}
        \item $\binom{n}{k} = O\left(\frac{n^k}{k!}\right)$ - wielomianowe względem $n$ dla stałego $k$
        \item $k!$ - silniowe względem $k$
        \item $\binom{\binom{n}{k}}{m} \approx O((n^k)^m)$ dla dużych $n$
        \item $(k!)^m$ - wykładnicze względem $m$
    \end{itemize}

    \subsubsection{Złożoność pamięciowa}
    \label{subsubsec:zlozonosc_pamieciowa}

    \textbf{Główne struktury danych:}

    \begin{enumerate}
        \item \textbf{missingEdgesMatrix:} $O\left(\binom{n}{k} \times k! \times k^2\right)$
        \begin{itemize}
            \item Tablica 2D o wymiarach $k! \times \binom{n}{k}$
            \item Każda komórka zawiera listę brakujących krawędzi (w najgorszym $O(k^2)$ krawędzi)
        \end{itemize}

        \item \textbf{indexToSubset:} $O\left(\binom{n}{k} \times k\right)$
        \begin{itemize}
            \item Przechowuje $\binom{n}{k}$ kombinacji, każda długości $k$
        \end{itemize}

        \item \textbf{indexToPermutation:} $O(k! \times k)$
        \begin{itemize}
            \item Przechowuje $k!$ permutacji, każda długości $k$
        \end{itemize}

        \item \textbf{Zmienne tymczasowe w głównej pętli:} $O(k^2)$
    \end{enumerate}

    \textbf{Całkowita złożoność pamięciowa:}
    \[
        S(n, k, m) = O\left(\binom{n}{k} \times k! \times k^2\right)
    \]

    \textbf{Uwaga:} Złożoność pamięciowa jest niezależna od $m$ (nie przechowujemy wszystkich $m$-krotek, generujemy je leniwie).

    \subsubsection{Charakterystyka algorytmu}
    \label{subsubsec:charakterystyka}

    \textbf{Klasa złożoności:}
    \begin{itemize}
        \item Problem jest \textbf{NP-trudny} (redukcja z problemu izomorfizmu podgrafów)
        \item Algorytm dokładny ma złożoność \textbf{wykładniczą} względem $k$ (ze względu na $k!$)
        \item Algorytm ma złożoność \textbf{wielomianowo-wykładniczą} względem $m$
    \end{itemize}

    \textbf{Praktyczne ograniczenia:}
    \begin{itemize}
        \item Algorytm jest wykonalny dla małych wartości $k$ ($k \leq 6-7$) i $n \leq 20$
        \item Dla większych wartości $k$ lub $n$ algorytm staje się niepraktyczny
        \item Wartość $m$ ma mniejszy wpływ na czas wykonania niż $k$ (dla małych $m$)
    \end{itemize}

    \subsection{Aproksymacyjne minimalne rozszerzenie multigrafu - algorytm pierwszy}
    \label{sec:minimalne_rozszerzenie_approx}

    \noindent
    Zdefiniowane są dwa skierowane multigrafy: mniejszy $G_1 = (V_1, E_1)$ oraz większy $G_2 = (V_2, E_2)$. Multigrafy $G_1$ i $G_2$ są reprezentowane przez macierze sąsiedztwa $A_{G_1}$ i $A_{G_2}$. Wartość komórki $A_{G_1}[i, j]$ oznacza liczbę krawędzi skierowanych od wierzchołka $i$ do wierzchołka $j$ w grafie $G_1$. Podana jest także liczba szukanych kopii $m$. Idea algorytmu polega na iteracyjnym znajdowaniu \textit{najtańszej} kopii $G_1$ w $G_2$.

    \subsubsection{Opis algorytmu}
    \begin{enumerate}
        \item Iteruj po wszystkich możliwych nasionach, czyli parach ($u_1$, $u_2$), gdzie $u_1 \in V_1$ i $u_2 \in V_2$.
        \item Ustal zerową macierz kosztu $C_{u_1, u_2}$ o rozmiarze $|V_2|$ na $|V_2|$, która reprezentuje jakie i ile krawędzi skierowanych należy dodać do $G_2$ dla danych nasion ($u_1$, $u_2$).
        \item Do mapowania dodaj takich sąsiadów nasion $u'_1 \in V_1$ i $u'_2 \in V_2$, które minimalizują koszt zdefiniowany wzorem:
        \begin{equation}
            Koszt = max(0, (A_{G_1}[u_1, u'_1] - A_{G_2}[u_2, u'_2])) + max(0, A_{G_1}[u'_1, u_1] - A_{G_2}[u'_2, u_2]))
        \end{equation}
        Zapisz do odpowiednich komórek macierzy $C_{u_1, u_2}$:
        \begin{equation}
            C_{u_1, u_2}[u_2,  u'_2] = C_{u_1, u_2}[u_2,  u'_2] + max(0, (A_{G_1}[u_1, u'_1] - A_{G_2}[u_2, u'_2]))
        \end{equation}
        \begin{equation}
            C_{u_1, u_2}[u'_2,  u_2] = C_{u_1, u_2}[u'_2,  u_2] + max(0, (A_{G_1}[u'_1, u_1] - A_{G_2}[u'_2, u_2]))
        \end{equation}
        \item Następnie próbuj zachłannie rozszerzyć mapowanie na resztę wierzchołków $G_1$. Do mapowania dodawaj tylko wierzchołki, które nie zostały jeszcze zmapowane.
        \item Ze wszystkich macierzy kosztu ($|V_1| \cdot |V_2|$ macierzy) wybierz $m$ najlepszych. Przez najlepszą macierz rozumiemy taką, dla której suma wartości we wszystkich komórkach jest najmniejsza. Każda macierz kosztu odpowiada jednemu mapowaniu - jeśli dowolna para z $m$ macierzy mapuje te same wierzchołki w $G_2$, wybierz kolejną $m+1$ najlepszą macierz kosztu i ponownie sprawdź warunek. Docelowo, żadna para z wybranych $m$ macierzy kosztu nie może mapować tych samych wierzchołków w $G_2$.
        \item Macierz $K$ o rozmiarze $|V_2|$ na $|V_2|$ skonstruuj w następujący sposób - $K[i, j] = max_{k=1,...,m}(C_k[i, j])$, gdzie $C_k$ dla $k=1,...,m$ to $m$ najlepszych macierzy kosztu.
        \item Zwróć macierz $K$ reprezentującą minimalne rozszerzenie.
    \end{enumerate}

    \subsubsection{Złożoność obliczeniowa}
    \noindent
    Pesymistyczna złożoność opisanego algorytmu aproksymacyjnego równa jest:
    \begin{equation}
        O(|V_1| \cdot |V_2| \cdot (|V_1| \cdot |E_1| \cdot |E_2|) \cdot m) = O(|V_1|^2 \cdot |V_2| \cdot |E_1| \cdot |E_2| \cdot m)
    \end{equation}
    Czynnik $|V_1| \cdot |V_2|$ odpowiada za iteracyjne wybieranie nasion do mapowania. Czynnik $|V_1| \cdot |E_1| \cdot |E_2|$ to koszt zachłannego przeszukiwania grafu w celu minimalizacji kosztu. $m$ to liczba wybieranych macierzy kosztu (liczba kopii). Opisany algorytm ma zatem złożoność wielomianową.

    \subsubsection{Uzasadnienie}

    \noindent
    Opisany algorytm jest heurystyką zachłanną naszego autorstwa. Algorytm gwarantuje, że macierz $K$ rzeczywiście uczyni $G_2$ rozszerzeniem zawierającym kopie $G_1$. \\ \\
    Z definicji każdej macierzy $C_{u_1, u_2}$ wpisy odpowiadają dokładnie brakującym krawędziom. Jeśli na końcu algorytm utworzy macierz $K$ zgodnie z opisem, to po dodaniu tych krawędzi w $G_2$ wszystkie odwzorowania skonstruowane przez algorytm staną się izomorficznymi (liczbowo zgodnymi) kopiami $G_1$. Zatem algorytm zwraca dopuszczalne rozwiązanie. \\ \\
    Niestety nie ma dowodu, że algorytm daje rozwiązanie optymalne, ani że ma stałą gwarancję aproksymacji. To heurystyka zachłanna — lokalnie wybiera najtańsze mapowanie — ale problem minimalnego rozszerzenia (znalezienie najmniejszego zbioru dodatkowych krawędzi, by powstały $m$ kopii) jest kombinatorycznie trudny i algorytm zachłanny może prowadzić do lokalnie optymalnych, ale globalnie złych decyzji.

% --------------------------------- ALGORYTM APROKSYMACYJNY 2 ---------------------------------
\subsection{Aproksymacyjne minimalne rozszerzenie multigrafu - algorytm drugi}
\label{sec:minimalne_rozszerzenie_approx_2}

Algorytm polega na losowym wybraniu $n$ k-elementowych podzbiorów wierzchołków z grafu $G$, a następnie użyciu pewnej heurystyki do stworzenia macierzy kosztów przypisania pomiędzy konkretnymi wierzchołkami z grafu $P$, oraz grafu $G$. Następnie na tej macierzy wywoływany jest Algorytm Węgierski, który znajduje najlepsze mapowanie wierzchołków, w sensie przyjętej heurystyki. Ta operacja jest powtarzana na każdym z $n$ podzbiorów, tak żeby uzyskać wymagane n podgrafów grafu $G$, różniących się przynajmniej jednym wierzchołkiem.

\subsubsection{Heurystyczna Funkcja Kosztu}

Algorytm Węgierski operuje na macierzy kosztów $M$, która stanowi heurystyczną aproksymację rzeczywistego kosztu rozszerzenia. Wybór tej heurystyki ma kluczowy wpływ na jakość znajdowanych rozwiązań -- lepsza heurystyka (bliższa rzeczywistemu kosztowi) sprawi, że najlepsze rozwiązania heurystyczne będzą z większym prawdopodobieństwem odpowiadać najlepszym rozwiązaniom rzeczywistym. \\

Poniżej przedstawiono sześć propozycji heurystyk do obliczania macierzy kosztów $M$, które chcielibyśmy poddać testom w celu wybrania funkcji dającej najlepsze rezultaty.

\begin{enumerate}
    \item \textbf{Heurystyka Różnicy Stopni.}
    Jest to najprostsza i najszybsza heurystyka. Zakłada, że wierzchołki o podobnej łącznej liczbie połączeń (niezależnie od kierunku) powinny być ze sobą mapowane. 
    
    \textbf{Wzór:}
    $$ M[i, j] = |\text{deg}_{\text{total}}(p_i) - \text{deg}_{\text{total}}(g_j)| $$
    gdzie $\text{deg}_{\text{total}}(v) = \text{deg}_{in}(v) + \text{deg}_{out}(v)$.
    
    \textbf{Złożoność budowy:} $\mathcal{O}(N^2 + k^2 + kN)$. Zdominowana przez wstępne obliczenie stopni: $\mathcal{O}(N^2)$.

    \item \textbf{Heurystyka Dopasowania Stopni Skierowanych.} % TODO: Dodaj opcje z roznym ignorowaniem roznicy, jesli w G jest wiecej niz w P
    Nieco bardziej zaawansowana wersja dla grafów skierowanych. Koszt $M[i, j]$ jest sumą absolutnych różnic stopni wejściowych i wyjściowych.
    
    \textbf{Wzór:}
    $$ M[i, j] = |\text{deg}_{in}(p_i) - \text{deg}_{in}(g_j)| + |\text{deg}_{out}(p_i) - \text{deg}_{out}(g_j)| $$
    
    \textbf{Złożoność budowy:} $\mathcal{O}(N^2 + k^2 + kN)$. Również zdominowana przez $\mathcal{O}(N^2)$.

    \item \textbf{Heurystyka Dopasowania Stopni Skierowanych z Ignorowaniem Nadmiaru.}
    Wersja modyfikowana poprzedniej heurystyki, która ignoruje nadmiar stopni w większym grafie. Pomaga to uniknąć karania wierzchołków w $G$ o większych stopniach niż ich odpowiedniki w $P$.

    \textbf{Wzór:}
    $$ M[i, j] = \max(0, \text{deg}_{in}(p_i) - \text{deg}_{in}(g_j)) + \max(0, \text{deg}_{out}(p_i) - \text{deg}_{out}(g_j)) $$

    \textbf{Złożoność budowy:} $\mathcal{O}(N^2 + k^2 + kN)$. Również zdominowana przez $\mathcal{O}(N^2)$.

    \item \textbf{Heurystyka Histogramu Stopni Sąsiadów.} % TODO: Sprawdz jak tworzyc te histogramy i liczyc ich odleglosc
    Ta heurystyka analizuje najbliższe otoczenie. Dla każdego wierzchołka $p_i$ i $g_j$ tworzony jest histogram stopni ich bezpośrednich sąsiadów. Koszt $M[i, j]$ to odległość między tymi dwoma rozkładami.
    
    \textbf{Wzór:}
    Niech $H_P(p_i)$ będzie histogramem stopni sąsiadów $p_i$, a $H_G(g_j)$ analogicznym histogramem dla $g_j$. Niech $S$ będzie większą z dwóch wartości stopni wierzchołków. Wtedy:
    $$ M[i, j] = \sum_{s=0}^{S} |H_P(p_i)[s] - H_G(g_j)[s]| $$
    Zakładamy, że histogramy są normalizowane do tej samej długości $S$.
    
    \textbf{Złożoność budowy:} Wymaga obliczenia stopni ($\mathcal{O}(N^2)$), zbudowania $N+k$ histogramów (w $\mathcal{O}(N^2)$) oraz obliczenia $kN$ odległości (w $\mathcal{O}(kN^2)$). Całkowity koszt to $\mathcal{O}(N^2 + kN^2)$.

    \item \textbf{Heurystyka Dopasowania Struktury (Liczba Trójkątów).}
    Ta heurystyka próbuje uchwycić naturę problemu przez mierzenie lokalnej struktury. Wierzchołek $p_i$ będący częścią wielu trójkątów powinien być mapowany na $g_j$, który również uczestniczy w wielu trójkątach.
    
    \textbf{Wzór:}
    $$ M[i, j] = \alpha \cdot |\text{deg}(p_i) - \text{deg}(g_j)| + \beta \cdot \max(0, \text{triangles}(p_i) - \text{triangles}(g_j)) $$
    gdzie $\text{triangles}(v)$ to liczba trójkątów, w których uczestniczy wierzchołek $v$. Karany jest tylko niedobór trójkątów w $g_j$ względem $p_i$.
    
    \textbf{Złożoność budowy:} Zdominowana przez koszt zliczania trójkątów w grafie $G$, który wynosi $\mathcal{O}(N^3)$ (przy użyciu mnożenia macierzy).

    \item \textbf{Heurystyka Zachłannego Dopasowywania Sąsiadów.}
    Najbardziej złożona obliczeniowo, ale potencjalnie najdokładniejsza heurystyka. Próbuje bezpośrednio oszacować koszt w najbliższym otoczeniu. Koszt $M[i, j]$ jest sumą "najlepszych" możliwych dopasowań dla sąsiadów $p_i$ wśród sąsiadów $g_j$.
    
    \textbf{Wzór (koncepcyjny):}
    $$ M[i, j] = \sum_{p_k \in \mathcal{N}(p_i)} \left( \min_{g_l \in \mathcal{N}(g_j)} C(p_k, g_l) \right) $$
    gdzie $\mathcal{N}(v)$ to sąsiedztwo $v$, a $C$ to prosta heurystyka kosztu (np. z Opcji 1).
    
    \textbf{Złożoność budowy:} Dla prostej heurystyki wypełnienie tymczasowej macierzy kosztów, to koszt $\mathcal{O}(N^2)$. Wypełnienie jednej komórki $M[i, j]$ kosztuje $\mathcal{O}(\text{deg}(p_i) \cdot \text{deg}(g_j))$. W najgorszym przypadku dla grafów gęstych (gdy $\text{deg} \approx k$ lub $N$), całkowity koszt wypełnienia $kN$ komórek wynosi $\mathcal{O}(k^2 N^2)$. Czyli koszt całej heurystyki to $\mathcal{O}(N^2 + k^2 N^2)$, czyli $\mathcal{O}(k^2 N^2)$.
\end{enumerate}

\subsubsection{Opis Algorytmów}

Ta część opisuje dwie części algorytmu aproksymacyjnego: fazę generowania k-elementowych podzbiorów wierzchołków większego grafu oraz fazę znajdowania najlepszych mapowań dla tych podzbiorów. Lepsze rozwiązanie można uzyskać poprzez iterowanie po podzbiorach i znajdowanie najlepszych mapowań dla każdego z nich, np. korzystając z Algorytmu Murty'ego, jednak z powodu ograniczenia wielomianowej złożoności czasowej, w tej wersji algorytmu generujemy tylko $n$ podzbiorów.

\begin{enumerate}
    \item \textbf{Faza 1:} Najpierw generowana jest lista $\mathcal{L}$ $n$ $k$-elementowych podzbiorów wierzchołków z $G$ ($S \subset V_G$).
    \item \textbf{Faza 2:} Następnie, algorytm iteruje $n$ razy. W każdej iteracji $i$, bierze $i$-ty podzbiór $S_i$ z listy $\mathcal{L}$ i rozwiązuje dla niego \emph{mały} ($k \times k$) problem przypisania (Algorytmem Węgierskim), aby znaleźć najlepsze mapowanie $f_i: V_P \to S_i$. Znalezione rozszerzenie jest dodawane do grafu $G$.
\end{enumerate}

\textbf{Algorytm Fazy 1: Generowanie Podzbiorów}

Celem tej fazy jest szybkie wygenerowanie listy $\mathcal{L}$ $n$ unikalnych $k$-elementowych podzbiorów $V_G$.

\begin{algorithm}[H]
    \caption{Faza 1: Generowanie $n$ Pierwszych Podzbiorów Leksygograficznych}
    \label{alg:generate_subsets_lexical}
    \begin{algorithmic}[1]
        \Require Graf $G$ (o $N$ wierzchołkach, $V_G = \{v_1, \dots, v_N\}$), Liczba podzbiorów $n$, Rozmiar podzbioru $k$
        \Ensure Lista $\mathcal{L}$ (do $n$) unikalnych $k$-elementowych podzbiorów $V_G$
        
        \State $\mathcal{L} \gets []$
        
        \If{$n = 0$ \textbf{or} $k > N$}
            \State \Return $\mathcal{L}$
        \EndIf
        
        \State $\mathcal{C} \gets \Call{CombinationsGenerator}{V_G, k}$ \Comment{Inicjalizuj generator kombinacji $\binom{N}{k}$}
        
        \For{$i \gets 1$ \textbf{to} $n$}
            \If{$\mathcal{C}.\text{hasNext}()$}
                \State $S \gets \mathcal{C}.\text{next}()$ \Comment{Pobierz następny podzbiór, np. $\{v_1, ..., v_k\}$}
                \State $\mathcal{L}.\text{append}(S)$
            \Else
                \State \textbf{break} \Comment{Zakończ, jeśli jest mniej niż $n$ możliwych kombinacji}
            \EndIf
        \EndFor
        
        \State \Return $\mathcal{L}$
    \end{algorithmic}
\end{algorithm}

\textbf*{Dowód Poprawności (Faza 1)}
Poprawność procedury oznacza gwarancję zakończenia i zwrócenia listy $\mathcal{L}$ zawierającej $n$ (lub mniej, jeśli niemożliwe) unikalnych $k$-elementowych podzbiorów.
\begin{itemize}
    \item \textbf{Zakończenie:} Pętla \texttt{for} (linia 6) jest ściśle ograniczona przez $n$. W każdej iteracji wywoływana jest operacja \texttt{next()} generatora kombinacji. Generator ten zakończy działanie (zwracając \texttt{false} w linii 7) po wygenerowaniu wszystkich $\binom{N}{k}$ kombinacji. Ponieważ $n$ jest skończone, algorytm zawsze się zakończy.
    \item \textbf{Unikalność:} Standardowy generator kombinacji (leksykograficzny) z definicji produkuje każdą kombinację (podzbiór) dokładnie jeden raz. Ponieważ algorytm tylko pobiera elementy z tego generatora, lista $\mathcal{L}$ z definicji zawiera unikalne podzbiory.
    \item \textbf{Ilość Wyjścia:} Algorytm próbuje pobrać $n$ podzbiorów. Jeśli $n > \binom{N}{k}$, generator wyczerpie się wcześniej, a pętla zostanie przerwana (linia 10). Algorytm poprawnie zwróci $\binom{N}{k}$ podzbiorów, czyli wszystkie, które istnieją. W przeciwnym razie zwróci dokładnie $n$ podzbiorów.
\end{itemize}

\textbf*{Analiza Złożoności (Faza 1)}
Analiza ta dotyczy kosztu wygenerowania $n$ podzbiorów.
\begin{itemize}
    \item \textbf{Inicjalizacja (linie 1-5):} Generator jest inicjowany na pierwszym elemencie, np. $\{v_1, \dots, v_k\}$ w czasie $\mathcal{O}(k)$.
    \item \textbf{Pętla Główna (linie 6-12):} Wykonuje się $n$ razy.
    \item \textbf{Operacje w pętli:}
        \item Wygenerowanie \texttt{next()} (linia 8): Koszt wygenerowania następnej kombinacji leksykograficznej z poprzedniej jest w zamortyzowanym czasie stałym $\mathcal{O}(1)$, a w najgorszym przypadku wynosi $\mathcal{O}(k)$.
        \item Dodanie do listy $\mathcal{L}$ (linia 9): Wymaga skopiowania podzbioru o rozmiarze $k$, co ma koszt $\mathcal{O}(k)$.
    \item Koszt pętli wynosi $n \cdot \mathcal{O}(k)$.
\end{itemize}
\textbf{Całkowita złożoność obliczeniowa (Faza 1): $\mathcal{O}(n \cdot k)$.}

\textbf{Algorytm Fazy 2: Iteracyjne Rozwiązywanie i Rozszerzanie}

Faza 2 pobiera listę $\mathcal{L}$ $n$ podzbiorów-kandydatów i iteracyjnie znajduje najlepsze mapowanie $V_P \to S_i$ dla każdego $S_i \in \mathcal{L}$, stosując rozszerzenie do grafu $G$.

\begin{algorithm}[H]
    \caption{Faza 2: Iteracyjne Rozwiązywanie na Podzbiorach}
    \label{alg:solve_subsets}
    \begin{algorithmic}[1]
        \Require Lista podzbiorów $\mathcal{L}$, Oryginalny graf $A_G$, Wzorzec $A_P$
        \Ensure Końcowa macierz $A_{final}$, Całkowity koszt $C_{total}$
        
        \State $A_{curr} \gets \Call{copy}{A_G}$
        \State $C_{total} \gets 0$
        
        \For{\textbf{each} $S_i$ \textbf{in} $\mathcal{L}$} \Comment{Iteruj $n$ razy}
            \State
            \State $D_{curr} \gets \Call{GetDegrees}{A_{curr}}$ \Comment{Tablica stopni wierzchołków w $A_{curr}$}
            \State $D_{P} \gets \Call{GetDegrees}{A_{P}}$ \Comment{Tablica stopni wierzchołków w $P$}
            \State
            \State $M_{sub} \gets \Call{Heurystyka}{S_i, A_{curr}, A_{P}, D_{curr}, D_{P}}$ \Comment{Wypełnij $M_{sub}$ wagami}
            \State
            \State $f_i \gets \Call{HungarianAlgorithm}{M_{sub}}$ \Comment{Wywołaj Algorytm Węgierski}
            
            \State
            \State $cost_i \gets 0$ \Comment{Zastosuj rozszerzenie dla tego mapowania}
            \For{$u \gets 1$ \textbf{to} $k$} \Comment{Iteruj $k \times k$ w macierzy wzorca $P$}
                \For{$v \gets 1$ \textbf{to} $k$}
                    \State $g_u \gets f_i(u)$
                    \State $g_v \gets f_i(v)$
                    \State $w_{needed} \leftarrow A_P[u, v]$
                    \State $w_{current} \leftarrow A_{curr}[g_u, g_v]$
                    \If{$w_{needed} > w_{current}$}
                        \State $w_{missing} \leftarrow w_{needed} - w_{current}$
                        \State $A_{curr}[g_u, g_v] \leftarrow w_{needed}$
                        \State $cost_i \gets cost_i + w_{missing}$
                    \EndIf
                \EndFor
            \EndFor
            \State $C_{total} \gets C_{total} + cost_i$
        \EndFor
        
        \State $A_{final} \gets A_{curr}$
        \State \Return $A_{final}, C_{total}$
    \end{algorithmic}
\end{algorithm}

\paragraph{Dowód Poprawności (Faza 2)}
Poprawność procedury (Algorytm \ref{alg:solve_subsets}) opiera się na dwóch głównych filarach: gwarancji zakończenia oraz poprawności iteracyjnego rozszerzania grafu.

\begin{itemize}
    \item \textbf{Zakończenie:} 
    Algorytm składa się z jednej głównej pętli \texttt{for} (linia 2), która iteruje po liście $\mathcal{L}$. Ponieważ lista $\mathcal{L}$ jest skończona (zawiera $n$ podzbiorów), pętla \texttt{for} wykona się $n$ razy.
    Musimy przeanalizować operacje wewnątrz pętli:
    \begin{enumerate}
        \item \texttt{GetDegrees} (linie 5-6): Obliczenie stopni dla macierzy $N \times N$ i $k \times k$ jest operacją o skończonej, wielomianowej złożoności (odpowiednio $\mathcal{O}(N^2)$ i $\mathcal{O}(k^2)$).
        \item \texttt{Heurystyka} (linia 8): Wypełnienie macierzy $k \times k$ jest operacją o złożoności zależnej od wybranej heurystyki. Dla prostszych heurystyk, jak liczenie różnicy stopni, przy podanej macierzy stopni i przy wielkości macierzy kosztów $k \times k$, jej złożoność to $\mathcal{O}(k^2)$.
        \item \texttt{HungarianAlgorithm} (linia 10): Wywołanie Algorytmu Węgierskiego na macierzy $k \times k$ ma złożoność wielomianową $\mathcal{O}(k^3)$.
        \item Pętla rozszerzenia (linie 13-25): Jest to zagnieżdżona pętla wykonująca $k \times k = k^2$ operacji $\mathcal{O}(1)$, stąd jej koszt to $\mathcal{O}(k^2)$.
    \end{enumerate}
    Ponieważ $n, k, N$ są skończone, a wszystkie operacje wewnątrz pętli głównej mają skończoną, wielomianową złożoność, cały algorytm gwarantuje zakończenie działania.

    \item \textbf{Poprawność Rozszerzenia:} 
    Musimy udowodnić, że końcowy graf $A_{final}$ zawiera $n$ podgrafów izomorficznych z $P$, zgodnie ze znalezionymi mapowaniami $f_1, \dots, f_n$.
    Niech $A_{curr}^{(i)}$ będzie stanem macierzy $A_{curr}$ na \emph{początku} $i$-tej iteracji pętli \texttt{for} (gdzie $A_{curr}^{(1)} = A_G$). Niezmiennik: $A_{curr}^{(i)}$ zawiera podgrafy $f_1, \dots, f_{i-1}$.
    \begin{itemize}
        \item \textbf{Baza ($i=1$):} $A_{curr}^{(1)} = A_G$. Niezmiennik jest trywialnie prawdziwy (zawiera 0 podgrafów).
        \item \textbf{Krok Indukcyjny:} Zakładamy, że $A_{curr}^{(i)}$ zawiera $f_1, \dots, f_{i-1}$. W $i$-tej iteracji algorytm znajduje nowe mapowanie $f_i$ (linie 5-10). Następnie pętla rozszerzenia (linie 13-25) iteruje przez wszystkie $k^2$ par w $P$. W linii 19, algorytm sprawdza, czy wymagana krawędź $(f_i(u), f_i(v))$ o krotności $w_{needed}$ istnieje. Jeśli nie ($w_{needed} > w_{current}$), algorytm \emph{dodaje} brakujące krawędzie (lub zwiększa krotność) w linii 21 ($A_{curr}[g_u, g_v] \leftarrow w_{needed}$). 
        \item Operacja ta jest monotoniczna: krotności krawędzi w $A_{curr}$ nigdy nie maleją ($A_{curr}^{(i+1)} \ge A_{curr}^{(i)}$).
        \item Zatem, po zakończeniu pętli (linii 13-25), graf $A_{curr}^{(i+1)}$ gwarantuje zawarcie podgrafu $f_i$. Ponieważ krawędzie są tylko dodawane, $A_{curr}^{(i+1)}$ nadal zawiera wszystkie poprzednie podgrafy $f_1, \dots, f_{i-1}$.
        \item \textbf{Zakończenie:} Po $n$ iteracjach, $A_{final} = A_{curr}^{(n+1)}$ zawiera wszystkie $n$ podgrafów $f_1, \dots, f_n$.
    \end{itemize}
    Algorytm poprawnie również sumuje koszt $C_{total}$ jako sumę kosztów $cost_i$ poniesionych w każdej iteracji, odzwierciedlając fakt, że krawędzie dodane we wcześniejszych iteracjach zmniejszają koszt rozszerzeń w późniejszych iteracjach.
\end{itemize}

\paragraph{Analiza Złożoności (Faza 2)}
Analizujemy koszt obliczeniowy (czasowy) Algorytmu \ref{alg:solve_subsets} w zależności od $N$ (rozmiar $G$), $k$ (rozmiar $P$) oraz $n$ (liczba podzbiorów w $\mathcal{L}$).

\begin{itemize}
    \item \textbf{Operacje Wstępne (linie 1-2):} Kopiowanie macierzy $A_G$ ma koszt $\mathcal{O}(N^2)$.
    
    \item \textbf{Pętla Główna (linia 4):} Pętla \texttt{for} wykonuje się $n$ razy. Musimy przeanalizować koszt \emph{jednej} iteracji.
    
    \item \textbf{Koszt jednej iteracji (linie 6-27):}
    \begin{itemize}
        \item Linia 6, \texttt{GetDegrees(A\_curr)}: Wymaga przejścia przez macierz $N \times N$, aby obliczyć stopnie dla $A_{curr}$. Koszt: $\mathcal{O}(N^2)$.
        \item Linia 7, \texttt{GetDegrees(A\_P)}: Wymaga przejścia przez macierz $k \times k$. Koszt: $\mathcal{O}(k^2)$.
        \item Linia 9, \texttt{Heurystyka}: Wypełnia macierz $M_{sub}$ o rozmiarze $k \times k$. Zakładając, że stopnie są już obliczone, każda z $k^2$ komórek jest obliczana w czasie $\mathcal{O}(1)$. Koszt: $\mathcal{O}(k^2)$.
        \item Linia 11, \texttt{HungarianAlgorithm(M\_sub)}: Wywołanie Algorytmu Węgierskiego na macierzy $k \times k$. Koszt: $\mathcal{O}(k^3)$.
        \item Linie 14-26, Pętla rozszerzenia: Zagnieżdżone pętle \texttt{for} wykonują $k \times k$ iteracji. Wszystkie operacje wewnątrz (mapowanie, odczyt, zapis) mają koszt $\mathcal{O}(1)$. Koszt: $\mathcal{O}(k^2)$.
    \end{itemize}
    
    \item \textbf{Koszt całkowity jednej iteracji:} Sumując powyższe kroki:
    $$ C_{\text{iteracja}} = \mathcal{O}(N^2 + k^2 + k^2 + k^3 + k^2) = \mathcal{O}(N^2 + k^3) $$
    
    \item \textbf{Koszt Całkowity Fazy 2:} Całkowity koszt to koszt inicjalizacji plus $n$ razy koszt jednej iteracji.
    $$ C_{\text{Faza 2}} = \mathcal{O}(N^2) + \mathcal{O}(n \cdot (N^2 + k^3)) = \mathcal{O}(N^2 + n \cdot N^2 + n \cdot k^3) $$
\end{itemize}
\textbf{Całkowita złożoność obliczeniowa (Faza 2): $\mathcal{O}(n \cdot N^2 + n \cdot k^3)$.}

\subsubsection{Końcowa Analiza Złożoności}
\label{sec:final_complexity_v4}

Całkowity koszt algorytmu aproksymacyjnego v.4 to suma kosztów obu faz:
$$C_{\text{total}} = C_{\text{Faza 1}} + C_{\text{Faza 2}}$$
$$C_{\text{total}} = \mathcal{O}(nk) + \mathcal{O}(n \cdot N^2 + n \cdot k^3)$$

\textbf{Całkowita złożoność obliczeniowa algorytmu: $\mathcal{O}(nk) + \mathcal{O}(n \cdot N^2 + n \cdot k^3)$.}

\textbf*{Uwaga}
Złożoność ta jest drastycznie niższa niż $\mathcal{O}(J \cdot k \cdot N^3)$ poprzedniego algorytmu. Ceną za tę szybkość jest jakość heurystyki. Poprzedni algorytm (oparty na Murty'm) gwarantował znalezienie $n$ najlepszych rozwiązań (w sensie heurystyki $M$) spośród \emph{wszystkich} $\binom{N}{k}$ podzbiorów. Ten algorytm przeszukuje tylko $n$ preselekcjonowanych podzbiorów; jeśli optymalne rozwiązanie leży poza nimi, algorytm ten go nie znajdzie.

% \section{Testy}
% \section{Podsumowanie}


    \section{Bibliografia}

% \bibliographystyle{plain}
% \bibliography{refs}

\end{document}